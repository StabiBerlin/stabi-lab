{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction into Data Analysis with Python \n",
    " Basics (adapted from http://swcarpentry.github.io/python-novice-inflammation/)\n",
    "\n",
    "This Jupyter notebook contains the introduction on Python\n",
    "\n",
    "Authors:\n",
    "Demi Vasques\n",
    "(Jaap Geraerts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Storing data in Python\n",
    "\n",
    "Besides variables, there are other ways of storing data in Python. The two most common are:\n",
    "\n",
    "* lists\n",
    "* dictionaries\n",
    "\n",
    "While with lists we can store multiple values (but only values!), with dictionaries we can store values that are associated with keys! Let's see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below we have two lists: one with historical actors and the other with their birth dates\n",
    "historical_actors = ['Isabella I of Castile','Napoleon Bonaparte','Catherine the Great','Martin Luther','Queen Victoria']\n",
    "birth_dates = ['04/22/1451','08/15/1769','05/02/1729','11/10/1483','05/24/1819']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create a single dictionary with these two lists, with historical actors as keys and\n",
    "# their respective birth dates as values\n",
    "birth_actors = {'Isabella I of Castile':'04/22/1451','Napoleon Bonaparte':'08/15/1769','Catherine the Great':'05/02/1729',\n",
    "                'Martin Luther':'11/10/1483','Queen Victoria':'05/24/1819'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Manipulating data\n",
    "\n",
    "Two very basic and also very practical ways of manipulating data are:\n",
    "\n",
    "* slicing\n",
    "* for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Slicing\n",
    "\n",
    "**Very, very important** - In Python the index (the position of a value) starts at 0, so when slicing we have to keep this in mind! The first value of a list, for instance, has index 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Isabella I of Castile', 'Napoleon Bonaparte', 'Catherine the Great', 'Martin Luther', 'Queen Victoria']\n"
     ]
    }
   ],
   "source": [
    "# the entire list (our dataset)\n",
    "print(historical_actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Isabella I of Castile', 'Napoleon Bonaparte', 'Catherine the Great']\n",
      "['Isabella I of Castile', 'Napoleon Bonaparte', 'Catherine the Great']\n"
     ]
    }
   ],
   "source": [
    "# one may be interested only in the first three values of the dataset\n",
    "print(historical_actors[0:3]) # the first limit (the value before the ':') is included, but the second limit is not!\n",
    "print(historical_actors[:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Napoleon Bonaparte', 'Catherine the Great', 'Martin Luther', 'Queen Victoria']\n"
     ]
    }
   ],
   "source": [
    "# or perhaps, in the last four values of the data\n",
    "print(historical_actors[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Napoleon Bonaparte', 'Catherine the Great']\n",
      "['Catherine the Great', 'Martin Luther']\n"
     ]
    }
   ],
   "source": [
    "# or yet, only in the values in specific positions\n",
    "print(historical_actors[1:3])\n",
    "print(historical_actors[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For loops\n",
    "\n",
    "This is a technique used when we want to repeat the same task, several times, as for instance, for every value of the dataset. There are two main ways of performing for loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isabella I of Castile\n",
      "Napoleon Bonaparte\n",
      "Catherine the Great\n",
      "Martin Luther\n",
      "Queen Victoria\n",
      "04/22/1451\n",
      "08/15/1769\n",
      "05/02/1729\n",
      "11/10/1483\n",
      "05/24/1819\n"
     ]
    }
   ],
   "source": [
    "# first, we can 'call' values directly\n",
    "for actor in historical_actors:\n",
    "    print(actor)\n",
    "    \n",
    "for date in birth_dates:\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The birth of Isabella I of Castile was on 04/22/1451\n",
      "The birth of Napoleon Bonaparte was on 08/15/1769\n",
      "The birth of Catherine the Great was on 05/02/1729\n",
      "The birth of Martin Luther was on 11/10/1483\n",
      "The birth of Queen Victoria was on 05/24/1819\n"
     ]
    }
   ],
   "source": [
    "# second, we can 'call' values using their indexes \n",
    "# this is particularly useful when we have more than one list, for example\n",
    "\n",
    "for i in range(len(historical_actors)): \n",
    "    print('The birth of', historical_actors[i], 'was on', birth_dates[i])\n",
    "    \n",
    "# this reads as: for every index in the range of the length of the list containing the historical actors,\n",
    "# print their name and their birthdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Loading data\n",
    "\n",
    "Like everything so far, there exist many forms of importing (or loading) data to Python. Here we are going to use:\n",
    "\n",
    "* the **pandas** package (https://pandas.pydata.org/) for data analysis\n",
    "* **CSV** files (https://en.wikipedia.org/wiki/Comma-separated_values) for storing tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # importing a package tha deals with dates\n",
    "\n",
    "# let's load the the historical actors into a Python list\n",
    "historical_actors = pd.read_csv('actors_birthdate.csv')['historical_actors'].values.tolist()\n",
    "\n",
    "# and load the birth dates as well\n",
    "birth_dates = pd.read_csv('actors_birthdate.csv')['birth_dates'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Isabella I of Castile', 'Napoleon Bonaparte', 'Catherine the Great', 'Martin Luther', 'Queen Victoria']\n",
      "['04/22/1451', '08/15/1769', '05/02/1729', '11/10/1483', '05/24/1819']\n"
     ]
    }
   ],
   "source": [
    "print(historical_actors)\n",
    "print(birth_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Example: creating a network\n",
    "Now let's create a network of letters exchanged by historical actors, supposing that they could send letters to anyone in history, from past and future :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'letters_exchange.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-98bd99bd16d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# now we call the function to create the network with our date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# we need to give as input the name of the file where our data is stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_network_of_letters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'letters_exchange.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# after the network is created, we can check the degree of each node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-98bd99bd16d9>\u001b[0m in \u001b[0;36mcreate_network_of_letters\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# loading the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'senders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nationality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrecipients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recipients'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'letters_exchange.csv'"
     ]
    }
   ],
   "source": [
    "# first, we import the packages we believe we might need\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# then, we define a function to create the network from our data\n",
    "# a function itself has some steps within it\n",
    "def create_network_of_letters(filename):\n",
    "    \n",
    "    # loading the data\n",
    "    senders = pd.read_csv(filename)['senders'].values.tolist()\n",
    "    nations = pd.read_csv(filename)['nationality'].values.tolist()\n",
    "    recipients = pd.read_csv(filename)['recipients'].values.tolist()\n",
    "    \n",
    "    # initiating a graph (network)\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # adding nodes and links to the network\n",
    "    for i in range(len(senders)):\n",
    "        G.add_node(senders[i],birthplace=nations[i],name=senders[i])\n",
    "        G.add_node(recipients[i])\n",
    "        G.add_edge(senders[i],recipients[i])\n",
    "        \n",
    "    # return the final network    \n",
    "    return G\n",
    "\n",
    "# now we call the function to create the network with our date\n",
    "# we need to give as input the name of the file where our data is stored\n",
    "G = create_network_of_letters('letters_exchange.csv')\n",
    "\n",
    "# after the network is created, we can check the degree of each node\n",
    "# that is, an actor has corresponded with how many other actors\n",
    "print(G.degree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Example: visualisation\n",
    "\n",
    "Again, there are a myriad of possibilities for data visualisation too. We will now see a simple script to visualise the network, that we just created, of letters exchanged between historical actors of different periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, again, we import the packages that might be useful\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline\n",
    "\n",
    "# we set up the visualisation environment\n",
    "fig = plt.figure(figsize=(8,6), dpi=500)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# we calculate the position of the nodes in the layout\n",
    "pos = nx.fruchterman_reingold_layout(G)\n",
    "\n",
    "# we define the colors of the nodes based on their nationalties\n",
    "colors = {'Georgia': '#1a1a1a', 'Austria': '#EF4A42', 'US': '#9E9E9E', \\\n",
    "          'Italy': '#098137', 'France': '#501557', 'Greece': '#770808', \\\n",
    "          'Germany': '#d82a20', 'Unknown': '#FDE401', 'UK':'#00529F'}\n",
    "\n",
    "# we draw the network\n",
    "nx.draw_networkx_nodes(G, pos=pos, node_size=[d**3 for n,d in G.degree()], alpha=0.9, \\\n",
    "                       node_color=[colors[G.nodes[node]['birthplace']] for node in G])\n",
    "nx.draw_networkx_labels(G, pos=pos, labels=nx.get_node_attributes(G, 'name'), font_size=9)\n",
    "nx.draw_networkx_edges(G, pos=pos, width=1,alpha=0.3,edge_color='b')\n",
    "\n",
    "# we show the network on the screen\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary script to create data of letters exchanged\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "senders = pd.read_csv('actors_birthplace.csv')['Senders'].values.tolist()\n",
    "places = pd.read_csv('actors_birthplace.csv')['Nationality'].values.tolist()\n",
    "\n",
    "send = []\n",
    "nat = []\n",
    "recip = []\n",
    "\n",
    "for i in range(len(senders)):\n",
    "    n = random.choice(np.random.geometric(1/float(4),15))\n",
    "    send.extend([senders[i]]*n)\n",
    "    nat.extend([places[i]]*n)\n",
    "    for i in range(n):\n",
    "        r = random.choice(senders)\n",
    "        recip.append(r)\n",
    "        \n",
    "rows = zip(send,nat,recip)\n",
    "\n",
    "with open('letters_exchange.csv','w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['senders','nationality','recipients'])\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
